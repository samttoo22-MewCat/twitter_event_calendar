# UCanScrapeX - X.com 推文爬蟲

這是一個基於 Selenium 的高穩定性網路爬蟲，專為高效提取 X.com（前身為 Twitter）的推文資料而設計。此工具透過利用瀏覽器設定檔來實現持久性登入，有效應對反爬取機制。它專注於收集最核心的推文資訊：內文、發文時間和原始連結。

## 主要功能

- **持久性登入**：僅需一次手動登入。您的登入狀態會被儲存至使用者設定檔中，後續執行時即可自動登入。
- **指定目標抓取**：可爬取任何指定使用者個人頁面上的推文。
- **聚焦核心資料**：提取您最需要的核心資料：
  - **推文文字**（已清理UI雜訊）
  - **精確發文時間戳**（UTC 標準時間）
  - **推文的永久網址**
- **進階過濾選項**：
  - **忽略轉推**：可選擇性自動跳過轉推，專注於原創內容。
  - **忽略置頂推文**：可選擇性地排除置頂推文。
- **智慧文字清理**：能智慧地移除推文文字中的UI元素（如作者資訊、互動按鈕、觀看次數等），並同時支援英文與中文介面。
- **結構化輸出**：將抓取到的資料儲存為結構化的 JSON 檔案，並以「時間戳＋使用者名稱」的格式自動命名（例如 `20251001_153000_username.json`），存放於專門的 `outputs/` 資料夾中。
- **除錯模式**：提供可選的除錯模式，會印出每則推文的「原始文字」與「清理後文字」，方便您驗證與調整文字清理邏輯。

## 安裝指南

- **Python 3.11**：請確保您已安裝 Python。建議您在虛擬環境中執行此專案。
- **安裝依賴套件**：請在您的終端機中，移動到 `UCanScrapeX` 資料夾，並執行以下指令來安裝所需套件：
  ```bash
  pip install -r requirements.txt
  ```

## 如何使用

### 1. 設定爬蟲參數

打開 `example.py` 檔案並設定您想抓取的目標：

- `username_to_scrape`：設定您想爬取的 X.com 使用者名稱（例如：`"ugcxvjk"`）。
- `num_tweets`：設定您希望收集的推文數量。

### 2. 首次登入

第一次執行爬蟲時，您需要手動登入 X.com。這個步驟會將您的登入資訊（Cookies）儲存到 `profile1/` 資料夾中，讓爬蟲未來可以自動登入。

執行腳本：
```bash
python example.py
```

- 程式會打開一個 Chrome 瀏覽器視窗，並前往 X.com 的登入頁面。
- 請手動輸入您的帳號密碼完成登入。
- 成功登入並看到 X.com 主頁後，回到您的終端機（Terminal）視窗，然後按下 **Enter** 鍵。

### 3. 後續執行

在所有後續的執行中，瀏覽器將會使用 `profile1/` 中儲存的登入資訊，因此您將會是已登入狀態。當腳本提示 "Press Enter when ready..." 時，您只需直接按下 **Enter** 即可開始爬取。

抓取到的資料將會以 JSON 檔案的形式，儲存在 `outputs/` 資料夾中。
