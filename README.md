# X (Twitter) 活動日曆爬蟲系統

這是一個基於 Python 的 X (Twitter) 活動爬蟲系統，用於自動抓取特定用戶的推文，並從中提取活動資訊，生成結構化的活動日曆資料。

## 主要功能

- 🤖 **自動爬蟲**：定時自動抓取多個 X (Twitter) 帳號的推文
- 🌐 **網站爬蟲**：直接從 SB玩具間官網抓取活動日曆
- 📅 **智能日期解析**：自動識別推文中的日期、時間資訊（支持全形/半形字符）
- 🎨 **圖形化介面**：提供友善的 Tkinter GUI 介面
- 📝 **手動編輯**：支援手動校正和編輯活動資訊
- 🌐 **網站同步**：一鍵將活動資料同步到網站日曆
- 💾 **資料持久化**：自動保存並管理活動資料（JSON 格式）
- 🔐 **會話管理**：登入一次後自動保存會話，無需重複登入

## 技術架構

### 核心技術
- **爬蟲引擎**：[UCanScrapeX](https://github.com/samttoo22-MewCat/UCanScrapeX)（基於 SeleniumBase UC 模式，規避反爬蟲機制）
- **GUI 框架**：Tkinter
- **日期解析**：datefinder + 自定義正則表達式
- **時區處理**：pytz（台灣時間 UTC+8）

### 項目結構

```
twitter_event_calendar/
├── UI_main.py                    # 主程式（GUI 介面）
├── SB_crawler.py                 # SB玩具間網站爬蟲
├── crawler_API.py                # 舊版爬蟲 API（已棄用）
├── requirement.txt               # Python 依賴套件
├── .gitignore                    # Git 忽略規則
├── README.md                     # 本文件
├── index (1).html                # 活動日曆網頁
├── category_config.json          # 活動分類配置檔案
├── user_config.json              # 爬取帳號配置檔案
│
├── UCanScrapeX/                  # 爬蟲模組
│   ├── __init__.py              # 模組初始化
│   ├── seleniumbase_crawler.py  # 爬蟲核心類
│   ├── example.py               # 使用範例
│   ├── requirements.txt         # 模組依賴
│   ├── README.md                # 英文說明
│   └── zh_TW_README.md          # 中文說明
│
├── outputs/                      # 活動資料輸出目錄
│   ├── 拘久屋_events.json
│   ├── 玩具間_events.json
│   ├── 更衣間_events.json
│   ├── 思_events.json
│   ├── 動物方程式_events.json
│   └── 其他_events.json
│
└── profile1/                     # 瀏覽器配置文件（會話資料）
```

## 安裝說明

### 系統需求
- Python 3.11
- Chrome 瀏覽器

### 安裝步驟

1. **克隆專案**
```bash
git clone <repository-url>
cd twitter_event_calendar
```

2. **安裝依賴**
```bash
pip install -r requirement.txt
```

依賴套件包括：
- `seleniumbase` - 爬蟲框架（透過 [UCanScrapeX](https://github.com/samttoo22-MewCat/UCanScrapeX) 整合）
- `datefinder` - 日期解析
- `pytz` - 時區處理

**關於 UCanScrapeX**：  
本專案使用自訂的 UCanScrapeX 爬蟲模組，該模組已整合在 `UCanScrapeX/` 目錄中。UCanScrapeX 提供：
- 持久化登入會話（只需登入一次）
- UC 模式防偵測機制
- 智能推文過濾（忽略轉推、置頂推文）
- 自動化錯誤重試機制

更多資訊請訪問：https://github.com/samttoo22-MewCat/UCanScrapeX

## 使用方法

### 啟動程式

```bash
python UI_main.py
```

### 首次使用

1. **登入 X (Twitter)**
   - 點擊「手動登入 X」按鈕
   - 在彈出的瀏覽器視窗中完成登入
   - 登入完成後關閉訊息提示框即可
   - 會話資料會保存在 `profile1/` 目錄，下次啟動無需重新登入

2. **設定爬蟲參數**
   - **爬蟲間隔**：設定自動執行的時間間隔（小時）
   - **抓取數量**：每次抓取的推文數量

3. **執行爬蟲**
   - **手動執行一次**：立即執行一次爬蟲（會同時爬取 X 推文和 SB 官網）
   - **啟動爬蟲**：按設定的間隔定時自動執行
   - **停止爬蟲**：停止定時執行

## 管理活動資料

#### 查看活動
- 在介面上方的分頁中選擇場地
- 雙擊日期項目查看該日期的活動詳情

#### 管理爬取帳號
1. 點擊「管理爬取帳號」按鈕開啟管理介面
2. 功能包括：
   - **新增帳號**：輸入使用者 ID 和顯示名稱（場地）
   - **編輯帳號**：修改現有帳號的資訊（雙擊項目或選中後點編輯）
   - **刪除帳號**：移除不需要的爬取對象
3. 帳號配置會保存在 `user_config.json` 中

#### 手動新增活動
1. 點擊「手動增加活動」按鈕
2. 在彈出視窗中填寫活動資訊：
   - **日期**：格式為 `YYYY-MM-DD`
   - **場地**：從下拉選單選擇
   - **標題**：活動名稱
   - **開始/結束時間**：格式為 `HH:MM`
   - **連結**：相關網址（選填）
   - **分類**：選擇活動類別（sp/bd/bds/so/wk/ss/hy/or）
3. 點擊「保存活動」完成新增

#### 編輯活動
在活動詳情視窗中可以編輯：
- **活動日期**：格式為 `YYYY-MM-DD` 或 `N/A`
- **活動名稱**：活動標題
- **簡短描述**：活動簡介
- **開始時間**：格式為 `HH:MM`
- **結束時間**：格式為 `HH:MM`
- **連結**：相關網址
- **分類**：活動類別代碼

編輯完成後點擊「保存校正」按鈕。

#### 刪除活動
- 點擊「刪除活動」按鈕標記為刪除（不會永久移除）
- 已刪除的活動不會顯示在主列表中
- 已刪除的活動不會同步到網站
- 可以點擊「取消刪除」恢復活動

#### 管理活動分類
1. 點擊「管理類別」按鈕開啟分類管理介面
2. 功能包括：
   - **新增類別**：設定代碼、名稱、顏色漸層（輸入起始和結束色碼）
   - **編輯類別**：修改名稱和顏色（雙擊項目或選中後點編輯）
   - **刪除類別**：移除不需要的分類
3. 分類配置會保存在 `category_config.json` 中

#### 從 HTML 導入活動
1. 點擊「從 HTML 導入活動」按鈕
2. 選擇包含活動資料的 HTML 檔案
3. 系統會自動解析並按場地分類保存
4. 導入的活動會自動標記為已校正（`check=true`）

## 同步到網站

點擊「同步網站」按鈕，系統會：
1. 彈出檔案選擇對話框，選擇要同步的 HTML 檔案
2. 讀取所有已校正且未刪除的活動
3. 檢查並處理未知類別（可選擇自動生成）
4. 按年月分組活動資料
5. 同步類別定義到 HTML
6. 更新 HTML 中的活動資料和類別配置

## 支援的日期時間格式

### 日期格式
- `9/13`、`09/13` - 月/日（自動補年份）
- `9-13`、`09-13` - 月-日
- `9／13`、`09／13` - 全形斜線
- `9－13` - 全形減號
- 完整日期格式（由 datefinder 處理）

### 時間格式
- `19:00~22:00`、`19:00-22:00` - 標準格式
- `19：00～22：00` - 全形字符
- `19點-22點`、`19點～22點` - 中文格式
- `7pm-10pm` - 12小時制
- `晚上七點-十點` - 中文口語化

## 資料格式

### JSON 事件格式

```json
{
    "date": "2025-10-10",
    "text": "原始推文內容",
    "title": "活動標題",
    "brief_description": "活動描述",
    "start_time": "19:00",
    "end_time": "22:00",
    "link": "https://example.com",
    "venue": "場地名稱",
    "category": "sp",
    "check": false,
    "delete": false
}
```

### 欄位說明
- `date`: 活動日期（YYYY-MM-DD 格式）
- `text`: 原始推文文字
- `title`: 活動名稱
- `brief_description`: 活動簡介
- `start_time`: 開始時間
- `end_time`: 結束時間
- `link`: 相關連結
- `venue`: 場地名稱
- `category`: 活動分類代碼（sp/bd/bds/so/wk/ss/hy/or）
- `check`: 是否已校正（true/false）
- `delete`: 是否已刪除（true/false）

### 預設活動分類
- `sp`: SP（拍打）
- `bd`: 束縛
- `bds`: 繩縛
- `so`: 交流
- `wk`: 工作坊
- `ss`: 特殊主題
- `hy`: 催眠
- `or`: 其他

### 分類配置格式（category_config.json）

```json
{
    "sp": {
        "name": "SP",
        "color": "linear-gradient(135deg, #e74c3c, #c0392b)"
    },
    "bd": {
        "name": "束縛",
        "color": "linear-gradient(135deg, #8e44ad, #9b59b6)"
    }
}
```

## 注意事項

⚠️ **重要提醒**

1. **時區設定**：系統使用台灣時間（UTC+8）處理所有時間
2. **會話保持**：首次登入後，會話資料保存在 `profile1/` 目錄，請勿刪除
3. **資料備份**：建議定期備份 `outputs/` 目錄中的 JSON 文件
4. **爬蟲引擎**：本專案使用 [UCanScrapeX](https://github.com/samttoo22-MewCat/UCanScrapeX)，採用 UC 模式的 SeleniumBase 來規避 X 的反爬蟲機制
5. **推文數量限制**：某些帳號可能因為推文較少而無法達到設定的抓取數量

## 常見問題

### Q: 為什麼顯示「沒有抓到足夠的推文」？
A: 這可能是因為：
- 該用戶的推文數量本身就較少
- 已經抓取過最新的推文（避免重複）
- 網路連線問題

### Q: 日期解析錯誤怎麼辦？
A: 系統會自動跳過無法解析的推文，您可以：
- 手動在 GUI 中編輯該活動的日期
- 檢查推文內容是否包含有效的日期格式

### Q: 如何新增/修改要爬取的 X 帳號？
A: 請點擊主介面上的「管理爬取帳號」按鈕。在彈出的視窗中，您可以方便地新增、編輯或刪除爬取列表中的帳號。

### Q: 手動新增的活動無法編輯或刪除？
A: 這個問題在 v2.1 版本後已修復。如果仍遇到問題，請確保您使用的是最新版本的程式。

### Q: 如何自定義活動分類？
A: 點擊「管理類別」按鈕：
1. 新增類別：輸入代碼（如 `test`）、名稱、起始色碼、結束色碼
2. 編輯類別：雙擊項目或選中後點擊編輯
3. 刪除類別：選中後點擊刪除（不會刪除使用該分類的活動）

### Q: 同步網站時出現「找不到已刪除的活動」？
A: v2.1 版本後已修復，已刪除的活動（`delete=true`）不會再同步到網站。

### Q: 時區比較錯誤（naive/aware datetime）？
A: v2.1 版本後已修復。系統現在統一使用台灣時區（UTC+8）處理所有日期時間。

## 開發者資訊

### 除錯模式
在 `_fetch_and_process_events()` 中設定 `debug=True` 可以查看：
- 原始推文文字
- 清理後的文字
- 爬蟲過程的詳細日誌

### 擴展功能
可以參考 `UCanScrapeX/example.py` 或訪問 [UCanScrapeX GitHub](https://github.com/samttoo22-MewCat/UCanScrapeX) 了解如何：
- 使用 XCrawler 類
- 自定義爬蟲參數
- 處理爬取結果
- 配置防偵測機制

## 授權

本專案僅供學習和個人使用。使用時請遵守 X (Twitter) 的服務條款。

## 貢獻

歡迎提交 Issue 和 Pull Request！

---

**最後更新：2025-10-08**
